---
layout: post
title: "index gs shop"
date: 2017-03-09 16:05:52 +0900
comments: true
categories: elasticsearch plugin "형태소 분석기"
---

### 도전 ###
  * GS SHOP의 방송편성표를 보여주는 웹 페이지를 작성
  * 관련 기술
  `Elasticsearch 플러그인`, `형태소 분석기`, `Thrift 서버`, `HAProxy`
  * 형태소 분석이 필요한 이유?  
  한국어 분석을 지원하지 않는다. 예를 들어 "아버지가 방에 들어간다"라는 한국어 문장을 인덱스해도 "아버지"로는 검색이 안 되고, 반드시 "아버지가"로 검색해야만 결과에 출력된다.
  * 형태소 분석기 - 은전 한  잎(mecab-ko)

### 설치 ###
외부에서 접근 가능한 환경을 구현하기 위해서 AWS를 이용하기로 했다.

Amazon Elasticsearch Service  

`search-buzzni-xusbuesxyq6c33zkupvvvmjof4.ap-northeast-2.es.amazonaws.com'`

``` python 연결확인
from datetime import datetime
from elasticsearch import Elasticsearch
host = 'search-buzzni-xusbuesxyq6c33zkupvvvmjof4.ap-northeast-2.es.amazonaws.com'
es = Elasticsearch([{'host': host,'port':80}])
print es.cluster.health()['status']

es.indices.create(index='my-index', ignore=400)
es.index(index="my-index", doc_type="test-type", id=42, body={"any": "data", "timestamp": datetime.now()})

es.get(index="my-index", doc_type="test-type", id=42)['_source']

```

### 해야 할 일 ###
  * 크롤링
    * `http://www.gsshop.com` 각 아이템의 세부 페이지 구하기
    * 세부 페이지에 방문해 제품에 대한 구체적인 정보 얻기
``` python 추후에 celery task에서 크롤링할 때 사용될 코드
# -*- coding: utf-8 -*-
import requests
from lxml import etree

home_url = 'http://www.gsshop.com'

def get_product(prod_url):
    url = "%s%s" % (home_url, prod_url)

    if 'http' in prod_url:
        url = prod_url
        return

    print url
    ele_response = requests.get(url)
    tree = etree.HTML(ele_response.content)
    price = tree.xpath("//span[contains(@class,'price-definition-ins')]/ins/strong")[0].text
    title = tree.xpath("//p[contains(@class,'product-title')]/text()")[0]
    # DOTO : 그외에 정보 추후 고려


def get_list_of_product():
    list_url = "%s%s" % (home_url, '/tv/tvScheduleMain.gs')
    response = requests.get(list_url)

    prod_urls = []
    tree = etree.HTML(response.content)
    for ele in tree.xpath("//tr/td/div[contains(@class, 'tdWrap')]/a"):
        if len(ele.text.strip()):
            prod_url = ele.xpath('@href')[0]
            prod_urls.append(prod_url)

    for url in prod_urls:
        print get_product(url)
```

  * 데이타 인덱스 - 위에서 얻어진 정보를 ES에 인덱싱하여 저장
  * 형태소 분석 - ES에서 한글은 지원하지 않는다고 하므로 별도의 형태소 분석기 필요
  * 주기적으로 GS SHOP 페이지 정보 얻어오기(Celery)

### 형태서 분석기 설치 ###
AWS에서 제공하는 Elasticsearch에 직접 한글 형태소 분석기를 직접 설치 할 수 있는 방법은 찾지 못했다. 따라서 별도의 EC2 인스턴스를 만들어 그 인스턴스와 Elasticsearch가 통신할 수 있으면 같은 효과를 얻을 수 있다고 생각하였다.


  * MECAB-KO 형태소 분석기 엔진
``` python
cd /tmp/
wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
tar -xvzf mecab-0.996-ko-0.9.2.tar.gz
cd mecab-0.996-ko-0.9.2
./configure
make
make check
sudo make install

```
  * MECAB-KO-DIC 사전(DICTIONARY) 파일

``` python
cd /tmp/
wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-1.6.1-20140814.tar.gz
tar -xvzf ./mecab-ko-dic-1.6.1-20140814.tar.gz
cd mecab-ko-dic-1.6.1-20140814
./autogen.sh
./configure
make
sudo make install
```

```
/usr/local/libexec/mecab/mecab-dict-index: error while loading shared libraries: libmecab.so.2: cannot open shared object file: no such file or directory
sudo ldconfig
grep /usr/local/lib
```

```
configure: error: Your compiler is not powerful enough to compile MeCab.
sudo yum install gcc-c++

```

  * MECAB-KO 형태소 분석기와 MECAB-KO-DIC 사전파일 확인
```
mecab -d /usr/local/lib/mecab/dic/mecab-ko-dic
```

  * LIBMECAB.SO, MECAB.JAR 설치
``` 
cd /tmp/
wget https://bitbucket.org/eunjeon/mecab-java/downloads/mecab-java-0.996.tar.gz
tar -xvzf mecab-java-0.996.tar.gz
cd mecab-java-0.996
vi Makefile
```

```
sudo cp libMeCab.so /usr/local/lib
sudo cp MeCab.jar /usr/local/lib

sudo chown -R $(whoami):$(whoami) /usr/local/lib/libMeCab.so
sudo chown -R $(whoami):$(whoami) /usr/local/lib/MeCab.jar
sudo chown -R $(whoami):$(whoami) /usr/local/lib/*mecab*

export JAVA_HOME=/usr/java/jdk1.8.0_60/

sudo ln -s $JAVA_HOME/include/linux/jni_md.h $JAVA_HOME/include/jni_md.h
sudo ln -s $JAVA_HOME/include/linux/jawt_md.h $JAVA_HOME/include/jawt_md.h

cd /tmp
wget https://bitbucket.org/eunjeon/mecab-ko-lucene-analyzer/downloads/elasticsearch-analysis-mecab-ko-0.16.1.zip

export ES=/usr/share/elasticsearch/

$ES/bin/plugin --install analysis-mecab-ko-0.16.1 --url file:///tmp/elasticsearch-analysis-mecab-ko-0.16.1.zip
```

### 결론 ###
  * 한글 형태의 text를 ES에 인덱싱하여 텍스트 풀서치를 하는 아주 일반적인 환경을 구축하는 요구사항이었다.
  * 외부에서 접근 가능한 형태를 위해 AWS ES를 선택했는데, 한글 형태소 분석을 위해서 별도의 모듈을 설치해야만 했다.
  * 다행히 Python에서 ES를 제어하기 위한 활성화된 패키지(https://github.com/elastic/elasticsearch-py)가 있어 기능 구현을 위해서 큰 어려움이 없을 것 같았다. 하지만 그러한 환경 구축에 경험이 없어서 대부분의 시간을 설치를 하는데 소비하였다. 
  * 결국은 요구한 미션을 마무리하지 못했다. 그 이유는
      * ES에서 plugin을 어떤식으로 제어하고 활용하는 방법에 대한 이해 부족
      * 전반적인 패키지 구성에 대한 경험이 없어 많은 시간을 소비
      * 형태소 분석기 설치 문서가 있지만, 조금 시간이 지나서 그런지 지금 버전과 맞지 않아 설치에 애를 먹음
  * 배움
    * AWS ES 설치는 생각보다 어렵지 않았다.
    * 은전한잎(mecab-ko)의 도움으로 형태소 분석이 가능하며, ES를 활용할 수 있다.


###  참고 ###
  * elasticsearch로 로그 검색 시스템 만들기
  http://d2.naver.com/helloworld/273788 
  * ELASTICSEARCH 한글 형태소 분석기(ANALYZER) 비교
  http://guruble.com/?p=437
  * 엘라스틱서치(elasticsearch)에 한글 형태소 분석기 은전한잎(eunjeon) 적용하기 - 
  http://blog.nacyot.com/articles/2015-06-13-eunjeon-with-elasticsearch/


|관계형 데이터베이스 |elasticsearch|
| --- | --- |
|Database|	Index|
|Table|	Type|
|Row|	Document|
|Column|	Field|
|Schema|	Mapping|
|Index|	Everything is indexed|
|SQL|	Query DSL|


